5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
    (3): Parameter containing: [torch.float32 of size 20x20]
    (4): Parameter containing: [torch.float32 of size 20x20]
)
5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
    (3): Parameter containing: [torch.float32 of size 20x20]
    (4): Parameter containing: [torch.float32 of size 20x20]
)
Trace: 24.44401321411133
Eigenvalues: 16.100915908813477
Iteration 1:
Training Loss: 5.482276916503906
Reconstruction Loss: -0.4605281352996826
Trace: 3.3892186737060546
Eigenvalues: 16.517919540405273
Iteration 1:
Training Loss: 5.622148036956787
Reconstruction Loss: -0.35863053798675537
Trace: 632.8276405334473
Eigenvalues: 75.14958953857422
Iteration 101:
Training Loss: 5.350534915924072
Reconstruction Loss: -0.49615779519081116
Trace: 225.85082202911377
Eigenvalues: 39.56616973876953
Iteration 101:
Training Loss: 5.556268692016602
Reconstruction Loss: -0.3843193054199219
Trace: 1575.77162109375
Eigenvalues: 240.3258056640625
Iteration 201:
Training Loss: 5.192633628845215
Reconstruction Loss: -0.4603964686393738
Trace: 3191.069716796875
Eigenvalues: 472.158447265625
Iteration 201:
Training Loss: 5.073696136474609
Reconstruction Loss: -0.38276994228363037
Trace: 5496.846528320312
Eigenvalues: 773.2484130859375
Iteration 301:
Training Loss: 4.81380033493042
Reconstruction Loss: -0.357590913772583
Trace: 6692.654482421875
Eigenvalues: 827.314453125
Iteration 301:
Training Loss: 4.616629600524902
Reconstruction Loss: -0.6418104767799377
Trace: 10022.45169921875
Eigenvalues: 1379.9468994140625
Iteration 401:
Training Loss: 4.558876037597656
Reconstruction Loss: -0.33115845918655396
Trace: 10447.25328125
Eigenvalues: 1036.8140869140625
Iteration 401:
Training Loss: 4.270377159118652
Reconstruction Loss: -0.6379355192184448
Trace: 13141.77017578125
Eigenvalues: 1567.66064453125
Iteration 501:
Training Loss: 4.110132694244385
Reconstruction Loss: -0.40364980697631836
Trace: 15283.1589453125
Eigenvalues: 1517.8482666015625
Iteration 501:
Training Loss: 3.820918560028076
Reconstruction Loss: -0.7721885442733765
Trace: 16798.51515625
Eigenvalues: 1771.312255859375
Iteration 601:
Training Loss: 3.73474383354187
Reconstruction Loss: -0.4985191524028778
Trace: 20545.7717578125
Eigenvalues: 1793.031982421875
Iteration 601:
Training Loss: 3.327558755874634
Reconstruction Loss: -1.0512104034423828
Trace: 20547.71755859375
Eigenvalues: 1933.770263671875
Iteration 701:
Training Loss: 3.4645392894744873
Reconstruction Loss: -0.5508996844291687
Trace: 22406.9045703125
Eigenvalues: 1810.295166015625
Iteration 701:
Training Loss: 2.9354262351989746
Reconstruction Loss: -1.2194901704788208
Trace: 21744.53685546875
Eigenvalues: 1909.632080078125
Iteration 801:
Training Loss: 3.2671072483062744
Reconstruction Loss: -0.6030803918838501
Trace: 23805.3
Eigenvalues: 1927.3404541015625
Iteration 801:
Training Loss: 2.6797399520874023
Reconstruction Loss: -1.3178833723068237
Trace: 23983.16119140625
Eigenvalues: 1945.57470703125
Iteration 901:
Training Loss: 3.0801737308502197
Reconstruction Loss: -0.6461455225944519
Trace: 25163.3530078125
Eigenvalues: 1943.7666015625
Iteration 901:
Training Loss: 2.471277952194214
Reconstruction Loss: -1.3992995023727417
Trace: 25636.1553125
Eigenvalues: 1951.375
Iteration 1001:
Training Loss: 2.901505708694458
Reconstruction Loss: -0.6823335886001587
Trace: 26981.63453125
Eigenvalues: 1968.2740478515625
Iteration 1001:
Training Loss: 2.2931482791900635
Reconstruction Loss: -1.469266653060913
