5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
    (3): Parameter containing: [torch.float32 of size 20x20]
    (4): Parameter containing: [torch.float32 of size 20x20]
    (5): Parameter containing: [torch.float32 of size 20x20]
)
5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
    (3): Parameter containing: [torch.float32 of size 20x20]
    (4): Parameter containing: [torch.float32 of size 20x20]
    (5): Parameter containing: [torch.float32 of size 20x20]
)
Trace: 126.97348243713378
Eigenvalues: 47.639427185058594
Iteration 1:
Training Loss: 5.4986419677734375
Reconstruction Loss: -0.4581286907196045
Trace: 76.9561703491211
Eigenvalues: 49.465797424316406
Iteration 1:
Training Loss: 5.70375919342041
Reconstruction Loss: -0.3538620173931122
Trace: 4336.979296875
Eigenvalues: 515.6493530273438
Iteration 101:
Training Loss: 4.992020130157471
Reconstruction Loss: -0.5682623982429504
Trace: 6933.403051757812
Eigenvalues: 899.4000244140625
Iteration 101:
Training Loss: 4.941967487335205
Reconstruction Loss: -0.563195526599884
Trace: 15893.480703125
Eigenvalues: 1951.2069091796875
Iteration 201:
Training Loss: 3.8903613090515137
Reconstruction Loss: -0.951452910900116
Trace: 16448.88216796875
Eigenvalues: 1877.966552734375
Iteration 201:
Training Loss: 4.104032516479492
Reconstruction Loss: -0.892020583152771
Trace: 21783.25595703125
Eigenvalues: 2101.55615234375
Iteration 301:
Training Loss: 3.216745376586914
Reconstruction Loss: -1.2157676219940186
Trace: 23938.6155078125
Eigenvalues: 2014.4716796875
Iteration 301:
Training Loss: 3.6774754524230957
Reconstruction Loss: -1.1376848220825195
Trace: 25751.5266796875
Eigenvalues: 2110.990234375
Iteration 401:
Training Loss: 2.770946979522705
Reconstruction Loss: -1.3582669496536255
Trace: 27031.59640625
Eigenvalues: 2162.957275390625
Iteration 401:
Training Loss: 3.0053141117095947
Reconstruction Loss: -1.4672105312347412
Trace: 27693.82595703125
Eigenvalues: 2025.550048828125
Iteration 501:
Training Loss: 2.2497785091400146
Reconstruction Loss: -1.507429838180542
Trace: 28609.6580078125
Eigenvalues: 2279.23974609375
Iteration 501:
Training Loss: 2.4877960681915283
Reconstruction Loss: -1.7643556594848633
Trace: 29787.025703125
Eigenvalues: 2053.73095703125
Iteration 601:
Training Loss: 1.8402831554412842
Reconstruction Loss: -1.6230477094650269
Trace: 27782.705078125
Eigenvalues: 1924.64990234375
Iteration 601:
Training Loss: 2.3720216751098633
Reconstruction Loss: -1.9351445436477661
Trace: 32128.01037109375
Eigenvalues: 1968.206298828125
Iteration 701:
Training Loss: 1.476007342338562
Reconstruction Loss: -1.7324246168136597
Trace: 29548.266328125
Eigenvalues: 2072.79296875
Iteration 701:
Training Loss: 1.8133161067962646
Reconstruction Loss: -2.1149709224700928
Trace: 28662.1959765625
Eigenvalues: 1977.60400390625
Iteration 801:
Training Loss: 1.0819268226623535
Reconstruction Loss: -1.8219456672668457
Trace: 29848.6453125
Eigenvalues: 2142.102294921875
Iteration 801:
Training Loss: 1.5327978134155273
Reconstruction Loss: -2.255815267562866
