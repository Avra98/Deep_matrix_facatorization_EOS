5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
)
5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
)
Trace: 17.826017560958864
Eigenvalues: 8.546388626098633
Iteration 1:
Training Loss: 5.6400227546691895
Reconstruction Loss: -0.46740806102752686
Trace: -16.002240562438963
Eigenvalues: 6.902987003326416
Iteration 1:
Training Loss: 5.643244743347168
Reconstruction Loss: -0.3224068880081177
Trace: -13.583625869750977
Eigenvalues: -9.45359992980957
Iteration 101:
Training Loss: 5.636593818664551
Reconstruction Loss: -0.4692389965057373
Trace: 15.70234706878662
Eigenvalues: 7.096078872680664
Iteration 101:
Training Loss: 5.641627788543701
Reconstruction Loss: -0.3229448199272156
Trace: 51.80789363861084
Eigenvalues: -16.849102020263672
Iteration 201:
Training Loss: 5.611049652099609
Reconstruction Loss: -0.4827841818332672
Trace: -2.38462703704834
Eigenvalues: 9.724793434143066
Iteration 201:
Training Loss: 5.6372809410095215
Reconstruction Loss: -0.32439273595809937
Trace: 1072.895464477539
Eigenvalues: 99.4861068725586
Iteration 301:
Training Loss: 5.203680992126465
Reconstruction Loss: -0.6188427209854126
Trace: 51.52557342529297
Eigenvalues: 18.208152770996094
Iteration 301:
Training Loss: 5.592519760131836
Reconstruction Loss: -0.3405553102493286
Trace: 2436.145920410156
Eigenvalues: 127.695556640625
Iteration 401:
Training Loss: 4.5963053703308105
Reconstruction Loss: -0.8936856985092163
Trace: 1126.234063720703
Eigenvalues: 108.33291625976562
Iteration 401:
Training Loss: 5.206113338470459
Reconstruction Loss: -0.36616963148117065
Trace: 3594.766142578125
Eigenvalues: 194.967041015625
Iteration 501:
Training Loss: 4.1151204109191895
Reconstruction Loss: -1.1148993968963623
Trace: 1812.1993432617187
Eigenvalues: 120.26559448242188
Iteration 501:
Training Loss: 4.864319801330566
Reconstruction Loss: -0.4886748194694519
Trace: 4489.700961914063
Eigenvalues: 240.30645751953125
Iteration 601:
Training Loss: 3.5993902683258057
Reconstruction Loss: -1.3977898359298706
Trace: 2695.314870605469
Eigenvalues: 154.47930908203125
Iteration 601:
Training Loss: 4.493881702423096
Reconstruction Loss: -0.5282982587814331
Trace: 3682.607041015625
Eigenvalues: 172.5757598876953
Iteration 701:
Training Loss: 4.230766773223877
Reconstruction Loss: -0.5796236991882324
Trace: 5231.576948242187
Eigenvalues: 271.30126953125
Iteration 701:
Training Loss: 3.202345371246338
Reconstruction Loss: -1.5567280054092407
Trace: 4553.60076171875
Eigenvalues: 207.90872192382812
Iteration 801:
Training Loss: 3.8457629680633545
Reconstruction Loss: -0.6636325120925903
Trace: 5861.19142578125
Eigenvalues: 293.0522766113281
Iteration 801:
Training Loss: 2.8725616931915283
Reconstruction Loss: -1.6515491008758545
Trace: 5446.79853515625
Eigenvalues: 228.0364532470703
Iteration 901:
Training Loss: 3.3710319995880127
Reconstruction Loss: -0.7373944520950317
Trace: 5991.654951171875
Eigenvalues: 312.8965759277344
Iteration 901:
Training Loss: 2.5955376625061035
Reconstruction Loss: -1.7461414337158203
Trace: 5801.472744140625
Eigenvalues: 249.3505859375
Iteration 1001:
Training Loss: 3.110060453414917
Reconstruction Loss: -0.7800407409667969
Trace: 6494.088159179688
Eigenvalues: 328.06829833984375
Iteration 1001:
Training Loss: 2.343602180480957
Reconstruction Loss: -1.8506542444229126
Trace: 6477.76947265625
Eigenvalues: 259.56097412109375
Iteration 1101:
Training Loss: 2.9326159954071045
Reconstruction Loss: -0.8315012454986572
Trace: 6584.40552734375
Eigenvalues: 344.3515625
Iteration 1101:
Training Loss: 2.1154026985168457
Reconstruction Loss: -1.9585111141204834
Trace: 6488.075546875
Eigenvalues: 274.06243896484375
Iteration 1201:
Training Loss: 2.7690844535827637
Reconstruction Loss: -0.8899672031402588
Trace: 6703.175146484375
Eigenvalues: 360.70062255859375
Iteration 1201:
Training Loss: 1.8884773254394531
Reconstruction Loss: -2.082543134689331
Trace: 6609.628759765625
Eigenvalues: 288.0558776855469
Iteration 1301:
Training Loss: 2.60656476020813
Reconstruction Loss: -0.9529162645339966
Trace: 7305.183525390625
Eigenvalues: 375.0869140625
Iteration 1301:
Training Loss: 1.684617042541504
Reconstruction Loss: -2.2041420936584473
Trace: 7271.614716796875
Eigenvalues: 300.0556640625
Iteration 1401:
Training Loss: 2.436575174331665
Reconstruction Loss: -1.017176866531372
Trace: 7326.968447265625
Eigenvalues: 389.9810791015625
Iteration 1401:
Training Loss: 1.4874558448791504
Reconstruction Loss: -2.3265762329101562
Trace: 7303.4623828125
Eigenvalues: 305.5849609375
Iteration 1501:
Training Loss: 2.2557883262634277
Reconstruction Loss: -1.080150842666626
Trace: 7614.105703125
Eigenvalues: 400.3993835449219
Iteration 1501:
Training Loss: 1.2997782230377197
Reconstruction Loss: -2.447643280029297
