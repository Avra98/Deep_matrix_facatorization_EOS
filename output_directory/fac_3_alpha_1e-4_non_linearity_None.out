5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
)
5
ParameterList(
    (0): Parameter containing: [torch.float32 of size 20x20]
    (1): Parameter containing: [torch.float32 of size 20x20]
    (2): Parameter containing: [torch.float32 of size 20x20]
)
Trace: -17.50303930282593
Eigenvalues: 11.415310859680176
Iteration 1:
Training Loss: 5.510250091552734
Reconstruction Loss: -0.5093477964401245
Trace: -1.228079719543457
Eigenvalues: 11.637275695800781
Iteration 1:
Training Loss: 5.642827987670898
Reconstruction Loss: -0.4042155146598816
Trace: 6.6657648849487305
Eigenvalues: 13.002058029174805
Iteration 101:
Training Loss: 5.503056049346924
Reconstruction Loss: -0.5124393701553345
Trace: 37.55831111907959
Eigenvalues: 15.737032890319824
Iteration 101:
Training Loss: 5.632671356201172
Reconstruction Loss: -0.4083552956581116
Trace: 142.25288902282716
Eigenvalues: 29.354656219482422
Iteration 201:
Training Loss: 5.422878742218018
Reconstruction Loss: -0.5517024993896484
Trace: 506.177313079834
Eigenvalues: 52.712608337402344
Iteration 201:
Training Loss: 5.330827713012695
Reconstruction Loss: -0.5184662342071533
Trace: 2809.375241699219
Eigenvalues: 123.4376449584961
Iteration 301:
Training Loss: 4.3679728507995605
Reconstruction Loss: -0.9304175972938538
Trace: 3317.0344140625
Eigenvalues: 132.1737518310547
Iteration 301:
Training Loss: 4.123856544494629
Reconstruction Loss: -0.8306860327720642
Trace: 4149.578916015625
Eigenvalues: 150.1908721923828
Iteration 401:
Training Loss: 3.584907293319702
Reconstruction Loss: -1.318278193473816
Trace: 3944.4661474609375
Eigenvalues: 138.1981658935547
Iteration 401:
Training Loss: 3.6431326866149902
Reconstruction Loss: -0.9740758538246155
Trace: 4787.504047851562
Eigenvalues: 151.81857299804688
Iteration 501:
Training Loss: 2.721162796020508
Reconstruction Loss: -1.8479640483856201
Trace: 4684.315966796875
Eigenvalues: 140.79656982421875
Iteration 501:
Training Loss: 2.970348596572876
Reconstruction Loss: -1.3113985061645508
Trace: 5749.24546875
Eigenvalues: 152.00376892089844
Iteration 601:
Training Loss: 1.5354632139205933
Reconstruction Loss: -2.5983142852783203
Trace: 5346.041904296875
Eigenvalues: 141.42904663085938
Iteration 601:
Training Loss: 2.0682685375213623
Reconstruction Loss: -1.9071851968765259
Trace: 5368.247915039063
Eigenvalues: 153.3385467529297
Iteration 701:
Training Loss: 0.5866091251373291
Reconstruction Loss: -3.2879526615142822
Trace: 5790.71529296875
Eigenvalues: 142.76927185058594
Iteration 701:
Training Loss: 1.3352103233337402
Reconstruction Loss: -2.5021369457244873
Trace: 5745.970458984375
Eigenvalues: 153.92733764648438
Iteration 801:
Training Loss: -0.15440945327281952
Reconstruction Loss: -3.884547472000122
Trace: 5995.362802734375
Eigenvalues: 144.7198028564453
Iteration 801:
Training Loss: 0.6467897891998291
Reconstruction Loss: -3.0721168518066406
Trace: 5655.9847021484375
Eigenvalues: 154.13404846191406
Iteration 901:
Training Loss: -0.8023573756217957
Reconstruction Loss: -4.436034202575684
Trace: 6001.615654296875
Eigenvalues: 146.9562530517578
Iteration 901:
Training Loss: -0.016718365252017975
Reconstruction Loss: -3.612384796142578
Trace: 5713.518334960938
Eigenvalues: 154.2277069091797
Iteration 1001:
Training Loss: -1.397706151008606
Reconstruction Loss: -4.954366683959961
Trace: 6239.2726953125
Eigenvalues: 149.024169921875
Iteration 1001:
Training Loss: -0.6400958299636841
Reconstruction Loss: -4.110759258270264
Trace: 5798.772177734375
Eigenvalues: 154.29550170898438
Iteration 1101:
Training Loss: -1.951075792312622
Reconstruction Loss: -5.4426445960998535
Trace: 6223.779111328125
Eigenvalues: 150.7290802001953
Iteration 1101:
Training Loss: -1.2017842531204224
Reconstruction Loss: -4.560074329376221
Trace: 5887.852001953125
Eigenvalues: 154.35662841796875
Iteration 1201:
Training Loss: -2.4658751487731934
Reconstruction Loss: -5.902143478393555
Trace: 6060.44111328125
Eigenvalues: 152.0580291748047
Iteration 1201:
Training Loss: -1.6912870407104492
Reconstruction Loss: -4.960864067077637
Trace: 5735.314912109375
Eigenvalues: 154.41213989257812
Iteration 1301:
Training Loss: -2.9428608417510986
Reconstruction Loss: -6.332995414733887
Trace: 5977.8480078125
Eigenvalues: 154.4609832763672
Iteration 1401:
Training Loss: -3.3802642822265625
Reconstruction Loss: -6.734136581420898
Trace: 6257.4108984375
Eigenvalues: 153.07373046875
Iteration 1301:
Training Loss: -2.110980987548828
Reconstruction Loss: -5.317690372467041
Trace: 5923.766884765625
Eigenvalues: 154.50228881835938
Iteration 1501:
Training Loss: -3.774082899093628
Reconstruction Loss: -7.103539943695068
Trace: 6285.620732421875
Eigenvalues: 153.84957885742188
Iteration 1401:
Training Loss: -2.46883225440979
Reconstruction Loss: -5.635486602783203
